<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aneesh Rangnekar</title>
  
  <meta name="author" content="Aneesh Rangnekar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aneesh Rangnekar</name>
              </p>
              <p>I am a final-year PhD Candidate in <a href="https://www.rit.edu/science/chester-f-carlson-center-imaging-science">The Chester F. Carlson Center for Imaging Science at Rochester Institute of Technology (RIT)</a>, where I work on developing and applying computer vision frameworks to hyperspectral imagery with my advisor, Dr. <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a> and my co-advisor, Dr. <a href="https://chriskanan.com/">Christopher Kanan</a>.
              </p>
              <p>
                My research is focused around three levels of hyperspectral data: aerial snapshot, nadir motion, and aerial motion. My goal is to develop data efficient computer vision modules and approaches that can process hyperspectral data streams to segment or detect vehicles in the imagery. For the past year, I have been also researching on semi-supervised learning and active learning to reduce labeling costs for semantic segmentation. I am looking forward to applying my skills towards remote sensing and ai4good.
              </p>
              <p style="text-align:center">
                <a href="mailto:aneesh.rangnekar@mail.rit.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2UtY2BIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
				<a href="https://www.linkedin.com/in/aneeshr31/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/aneesh3108">Github</a>				
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic.png"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		   <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/s4al.jpg' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2203.10730.pdf">
              <papertitle>Semantic Segmentation with Active Semi-Supervised Learning</papertitle>
              </a>
              <br>
	      <strong>Aneesh Rangnekar</strong>,
	      <a href="https://chriskanan.com/">Christopher Kanan</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>arXiv</em>, 2022
              <br>
              <p></p>
              <p>
              We improve the performance of semantic segmentation architectures on limited data with semi-supervised learning which inturn reduces the number of effective annotations required for active learning.
              </p>
            </td>
           </tr>
				
		   <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/rooftop_cvpr.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Semi-Supervised Hyperspectral Object Detection Challenge Results - PBVS 2022</papertitle>
              <br>
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
	      <a href="http://www.cvc.uab.es/~asappa/">Angel Sappa</a>,
	      <a href="https://ieee-aess.org/contact/erik-p-blasch">Erik Blasch</a>,
	      Jun Yu,
	      Liwen Zhang,
	      Shenshen Du,
	      Hao Chang,
	      Keda Lu,
	      Zhong Zhang,
	      Fang Gao,
	      Ye Yu,
	      Feng Shuang,
	      Lei Wang,
	      Qiang Ling,
	      Pranjay Shyam,
	      Kuk-Jin Yoon,
	      Kyung-Soo Kim
              <br>
	      <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2022
              <br>
	      <a href="papers/PBVS_2022_SSHODC_Paper.pdf">Paper</a>
	      <p></p>
              <p>
              We summarize the results of the first semi-supervised hyperspectral object detection challenge as a part of the PBVS workshop at CVPR.
              </p>
            </td>
           </tr>
		
		   <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/agu2021_checkerboard.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://agu.confex.com/agu/fm21/meetingapp.cgi/Paper/963097">
              <papertitle>Hyperspectral Camera Characterization of System Spectral Radiance Error for Spectral Identification of Reflective Objects Using Aerial Imagery</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <a href="https://www.linkedin.com/in/don-mckeown-73b824a/">Donald McKeown</a>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <strong>Aneesh Rangnekar</strong>,              
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>AGU Fall Meeting</em>, 2021
              <br>
	      <p></p>
              <p>
              We define and implement a spectral radiative transfer calibration image processing procedure for multispectral and hyperspectral imaging systems with a global shutter.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/waami2020_counting.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_1">
              <papertitle>Fine-Tuning for One-Look Regression Vehicle Counting in Low-Shot Aerial Datasets</papertitle>
              </a>
              <br>

              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.linkedin.com/in/yi-yao-b75137a">Yi Yao</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
              <a href="https://www.sri.com/bios/ajay-divakaran/">Ajay Divakaran</a>
              <br>
	      <em>Workshop on Analysis of Aerial Motion Imagery (WAAMI-ICPRW)</em>, 2020
              <br>
	      <a href="papers/WAAMI_2020__Counting.pdf">Paper</a>
	      <p></p>
              <p>
              We investigate the task of entity counting in overhead imagery from the perspective of re-purposing representations learned from ground imagery, e.g., ImageNet, via feature adaptation. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/dddas2020_uncertainty_hsi.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-61725-7_20">
              <papertitle>Uncertainty Estimation for Semantic Segmentation of Hyperspectral Imagery</papertitle>
              </a>
              <br>

              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
              <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>International Conference on Dynamic Data Driven Application Systems</em>, 2020
              <br>
	      <a href="papers/DDDAS20__Uncertainty_Estimation_in_HSI.pdf">Paper</a>
	      <p></p>
              <p>
              We investigate and adapt different existing frameworks for uncertainty quantification for semantic segmentation of hyperspectral imagery.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/dddas2020_occlusion.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-61725-7_39">
              <papertitle>Occlusion Detection for Dynamic Adaptation</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>International Conference on Dynamic Data Driven Application Systems</em>, 2020
              <br>
              <a href="papers/DDDAS_2020__Occlusion_Detection_for_Dynamic_Adaptation.pdf">Paper</a>
              <p></p>
              <p>
              We create a synthetic environment to map terrain and find occluded regions in the scene by integrating streams of real data with a physics-based simulation model that updates based on the most recent set of images.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/tgrs2020_aerorit.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9079478/">
              <papertitle>AeroRIT: A New Scene for Hyperspectral Image Analysis</papertitle>
              </a>
              <br>

              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.linkedin.com/in/nilaymokashi">Nilay Mokashi</a>, 
              <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
	      <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>Transactions on Geoscience and Remote Sensing</em>, 2020
              <br>
	      <a href="https://arxiv.org/pdf/1912.08178.pdf">arXiv</a> /
	      <a href="https://github.com/aneesh3108/AeroRIT">code</a>
	      <p></p>
              <p>
              We investigate applying different semantic segmentation architectures to the AeroRIT flight line by labeling every pixel for semantic scene understanding.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/pbvs2020_simulation.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w6/Mulhollan_Calibrated_Vehicle_Paint_Signatures_for_Simulating_Hyperspectral_Imagery_CVPRW_2020_paper.pdf">
                <papertitle>Calibrated Vehicle Paint Signatures for Simulating Hyperspectral Imagery</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <strong>Aneesh Rangnekar</strong>,
	      <a href="https://www.rit.edu/dirs/directory/tdbpci-timothy-bauch">Timothy Bauch</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
	      <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>
              <br>
	      <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2020
              <br>
	      <p></p>
              <p>
              We investigate a procedure for rapidly adding calibrated vehicle visible-near infrared (VNIR) paint signatures to an existing hyperspectral simulator - The Digital Imaging and Remote Sensing Image Generation (DIRSIG) model - to create more diversity in simulated urban scenes.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/tgrs2018_deephkcf.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8435971">
              <papertitle>Tracking in Aerial Hyperspectral Videos Using Deep Kernelized Correlation Filters</papertitle>
              </a>
              <br>

              <a href="https://uzkent.github.io/">Burak Uzkent</a>, 
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>Transactions on Geoscience and Remote Sensing</em>, 2018
              <br>
	      <a href="https://arxiv.org/pdf/1711.07235.pdf">arXiv</a> /
              <a href="https://github.com/buzkent86/HKCF_Tracker">code</a>
              <p></p>
              <p>
              We develop the Deep Hyperspectral Kernelized Correlation Filter based tracker (DeepHKCF) to efficiently track aerial vehicles using an adaptive multi-modal hyperspectral sensor.

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/arxiv2017_hsi_superresolution.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1712.08690.pdf">
              <papertitle>Aerial Spectral Super-Resolution using Conditional Adversarial Networks</papertitle>
              </a>

              <br>
              <strong>Aneesh Rangnekar</strong>,
	      <a href="https://www.linkedin.com/in/nilaymokashi">Nilay Mokashi</a>, 
	      <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
	      <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>arXiv</em>, 2017
              <br>

              <p></p>
              <p>
              We train a conditional adversarial network to learn an inverse mapping from a trichromatic space to 31 spectral bands within 400 to 700 nm.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/pbvs2017_likelihoodmaps.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w3/papers/Uzkent_Aerial_Vehicle_Tracking_CVPR_2017_paper.pdf">
                <papertitle>Aerial Vehicle Tracking by Adaptive Fusion of Hyperspectral Likelihood Maps</papertitle>
              </a>

              <br>
              <a href="https://uzkent.github.io/">Burak Uzkent</a>, 
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2017
              <br>
              <a href="https://github.com/buzkent86/CVPRW17_Paper_code">code</a>
              <p></p>
              <p>
              We propose a novel real-time hyperspectral likelihood maps-aided target detection and tracking method (HLT) inspired by an adaptive hyperspectral sensor.
              </p>
            </td>
          </tr>

        </tbody></table>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This website is adapted from Jon Barron's template (<a href="https://jonbarron.info/">site</a>, <a href="https://github.com/jonbarron/jonbarron_website">source code</a>)
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
