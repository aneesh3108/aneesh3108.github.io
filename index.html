<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aneesh Rangnekar</title>
  
  <meta name="author" content="Aneesh Rangnekar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aneesh Rangnekar</name>
              </p>
              <p>I am a Research Scholar at Memorial Sloan Kettering Cancer Center's Department of Medical Physics under Dr. Harini Veeraraghavan. My work is focused on machine learning for medical image analysis. Previously, I was a PhD student in <a href="https://www.rit.edu/science/chester-f-carlson-center-imaging-science">The Chester F. Carlson Center for Imaging Science at Rochester Institute of Technology (RIT)</a>, where I work on developing and applying computer vision frameworks to hyperspectral imagery with my advisor, Dr. <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a> and my co-advisor, Dr. <a href="https://chriskanan.com/">Christopher Kanan</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:rangnea@mskcc.org">Email (MSKCC)</a> &nbsp/&nbsp
		<a href="mailto:aneesh.rangnekar@gmail.com">Email (Personal)</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=2UtY2BIAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/aneesh3108">Github</a>				
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic.png"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/flare23_swinxseg.png' width="200">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/attachment?id=IlQQU5Pp5p&name=pdf">
              <papertitle>3D Swin Transformer for Partial Medical Auto Segmentation</papertitle>
              </a>
              <br>
        	      <strong>Aneesh Rangnekar</strong>,
        	      Jue Jiang,
              <a href="https://www.mskcc.org/profile/harini-veeraraghavan">Harini Veeraraghavan</a>
              <br>              
	          <em>MICCAI 2023 FLARE Challenge</em>, 2023
              <br>
              <a href="https://github.com/The-Veeraraghavan-Lab/FLARE23">code</a>
              <p></p>
              <p>
              To be filled.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			<img src='images/s4al.jpg' width="200">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Rangnekar_Semantic_Segmentation_With_Active_Semi-Supervised_Learning_WACV_2023_paper.pdf">
              <papertitle>Semantic Segmentation with Active Semi-Supervised Learning</papertitle>
              </a>
              <br>
        	      <strong>Aneesh Rangnekar</strong>,
        	      <a href="https://chriskanan.com/">Christopher Kanan</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	          <em> Winter Conference on Applications of Computer Vision (WACV)</em>, 2023
              <br>
              <a href="https://github.com/aneesh3108/S4AL">code</a>
              <p></p>
              <p>
              To be filled.
              </p>
            </td>
          </tr>
	
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/specAL.png' width="200">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SpecAL: Towards Active Learning for Semantic Segmentation of Hyperspectral Imagery</papertitle>
              </a>
              <br>
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
          	  <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	          <em>International Conference on Dynamic Data Driven Application Systems (DDDAS)</em>, 2022
              <br>
              <a href="papers/DDDAS_2022__SpecAL.pdf">Paper</a>
              <p></p>
              <p>
              To be filled.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/s4alplus.png' width="200">
            </td>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://bmvc2022.mpi-inf.mpg.de/0229.pdf">
              <papertitle>Semantic Segmentation with Active Semi-Supervised Representation Learning</papertitle>
              </a>
              <br>
        	      <strong>Aneesh Rangnekar</strong>,
        	      <a href="https://chriskanan.com/">Christopher Kanan</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	          <em>British Machine Vision Conference (BMVC)</em>, 2022
              <br>
    	          <a href="https://github.com/aneesh3108/S4AL_Plus">code</a>
              <p></p>
              <p>
              To be filled.
              </p>
            </td>
          </tr>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/rooftop_cvpr.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2022W/PBVS/papers/Rangnekar_Semi-Supervised_Hyperspectral_Object_Detection_Challenge_Results_-_PBVS_2022_CVPRW_2022_paper.pdf">
              <papertitle>Semi-Supervised Hyperspectral Object Detection Challenge Results - PBVS 2022</papertitle>
              <br>
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
        	      <a href="http://www.cvc.uab.es/~asappa/">Angel Sappa</a>,
        	      <a href="https://ieee-aess.org/contact/erik-p-blasch">Erik Blasch</a>,
        	      Jun Yu,
        	      Liwen Zhang,
        	      Shenshen Du,
        	      Hao Chang,
        	      Keda Lu,
        	      Zhong Zhang,
        	      Fang Gao,
        	      Ye Yu,
        	      Feng Shuang,
        	      Lei Wang,
        	      Qiang Ling,
        	      Pranjay Shyam,
        	      Kuk-Jin Yoon,
        	      Kyung-Soo Kim
              <br>
	      <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2022
              <br>
	      <p></p>
              <p>
              We summarize the results of the first semi-supervised hyperspectral object detection challenge as a part of the PBVS workshop at CVPR.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/agu2021_checkerboard.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://agu.confex.com/agu/fm21/meetingapp.cgi/Paper/963097">
              <papertitle>Hyperspectral Camera Characterization of System Spectral Radiance Error for Spectral Identification of Reflective Objects Using Aerial Imagery</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <a href="https://www.linkedin.com/in/don-mckeown-73b824a/">Donald McKeown</a>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <strong>Aneesh Rangnekar</strong>,              
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>AGU Fall Meeting</em>, 2021
              <br>
	      <p></p>
              <p>
              We define and implement a spectral radiative transfer calibration image processing procedure for multispectral and hyperspectral imaging systems with a global shutter.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/waami2020_counting.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_1">
              <papertitle>Fine-Tuning for One-Look Regression Vehicle Counting in Low-Shot Aerial Datasets</papertitle>
              </a>
              <br>

              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.linkedin.com/in/yi-yao-b75137a">Yi Yao</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
              <a href="https://www.sri.com/bios/ajay-divakaran/">Ajay Divakaran</a>
              <br>
	      <em>Workshop on Analysis of Aerial Motion Imagery (WAAMI-ICPRW)</em>, 2020
              <br>
	      <a href="papers/WAAMI_2020__Counting.pdf">Paper</a>
	      <p></p>
              <p>
              We investigate the task of entity counting in overhead imagery from the perspective of re-purposing representations learned from ground imagery, e.g., ImageNet, via feature adaptation. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/tgrs2020_aerorit.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9079478/">
              <papertitle>AeroRIT: A New Scene for Hyperspectral Image Analysis</papertitle>
              </a>
              <br>

              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.linkedin.com/in/nilaymokashi">Nilay Mokashi</a>, 
              <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
        	      <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>Transactions on Geoscience and Remote Sensing (TGRS)</em>, 2020
              <br>
	      <a href="https://arxiv.org/pdf/1912.08178.pdf">arXiv</a> /
	      <a href="https://github.com/aneesh3108/AeroRIT">code</a>
	      <p></p>
              <p>
              We investigate applying different semantic segmentation architectures to the AeroRIT flight line by labeling every pixel for semantic scene understanding.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/dddas2020_uncertainty_hsi.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-61725-7_20">
              <papertitle>Uncertainty Estimation for Semantic Segmentation of Hyperspectral Imagery</papertitle>
              </a>
              <br>
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
              <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>International Conference on Dynamic Data Driven Application Systems (DDDAS)</em>, 2020
              <br>
	      <a href="papers/DDDAS20__Uncertainty_Estimation_in_HSI.pdf">Paper</a>
	      <p></p>
              <p>
              We investigate and adapt different existing frameworks for uncertainty quantification for semantic segmentation of hyperspectral imagery.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/dddas2020_occlusion.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-61725-7_39">
              <papertitle>Occlusion Detection for Dynamic Adaptation</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>International Conference on Dynamic Data Driven Application Systems (DDDAS)</em>, 2020
              <br>
              <a href="papers/DDDAS_2020__Occlusion_Detection_for_Dynamic_Adaptation.pdf">Paper</a>
              <p></p>
              <p>
              We create a synthetic environment to map terrain and find occluded regions in the scene by integrating streams of real data with a physics-based simulation model that updates based on the most recent set of images.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/pbvs2020_simulation.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w6/Mulhollan_Calibrated_Vehicle_Paint_Signatures_for_Simulating_Hyperspectral_Imagery_CVPRW_2020_paper.pdf">
                <papertitle>Calibrated Vehicle Paint Signatures for Simulating Hyperspectral Imagery</papertitle>
              </a>
              <br>

              <a href="https://www.rit.edu/dirs/students/zachary-mulhollan">Zachary Mulhollan</a>,
              <strong>Aneesh Rangnekar</strong>,
	      <a href="https://www.rit.edu/dirs/directory/tdbpci-timothy-bauch">Timothy Bauch</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>,
	      <a href="https://www.rit.edu/dirs/directory/axvpci-anthony-vodacek">Anthony Vodacek</a>
              <br>
	      <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2020
              <br>
	      <p></p>
              <p>
              We investigate a procedure for rapidly adding calibrated vehicle visible-near infrared (VNIR) paint signatures to an existing hyperspectral simulator - The Digital Imaging and Remote Sensing Image Generation (DIRSIG) model - to create more diversity in simulated urban scenes.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/tgrs2018_deephkcf.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8435971">
              <papertitle>Tracking in Aerial Hyperspectral Videos Using Deep Kernelized Correlation Filters</papertitle>
              </a>
              <br>

              <a href="https://uzkent.github.io/">Burak Uzkent</a>, 
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	          <em>Transactions on Geoscience and Remote Sensing (TGRS)</em>, 2018
              <br>
    	          <a href="https://arxiv.org/pdf/1711.07235.pdf">arXiv</a> /
              <a href="https://github.com/buzkent86/HKCF_Tracker">code</a>
              <p></p>
              <p>
              We develop the Deep Hyperspectral Kernelized Correlation Filter based tracker (DeepHKCF) to efficiently track aerial vehicles using an adaptive multi-modal hyperspectral sensor.

              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/arxiv2017_hsi_superresolution.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1712.08690.pdf">
              <papertitle>Aerial Spectral Super-Resolution using Conditional Adversarial Networks</papertitle>
              </a>

              <br>
              <strong>Aneesh Rangnekar</strong>,
	      <a href="https://www.linkedin.com/in/nilaymokashi">Nilay Mokashi</a>, 
	      <a href="https://www.rit.edu/dirs/directory/ejipci-emmett-ientilucci">Emmett Ientilucci</a>, 
	      <a href="https://chriskanan.com/">Christopher Kanan</a>, 
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
	      <em>arXiv</em>, 2017
              <br>

              <p></p>
              <p>
              We train a conditional adversarial network to learn an inverse mapping from a trichromatic space to 31 spectral bands within 400 to 700 nm.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
			  <img src='images/pbvs2017_likelihoodmaps.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w3/papers/Uzkent_Aerial_Vehicle_Tracking_CVPR_2017_paper.pdf">
                <papertitle>Aerial Vehicle Tracking by Adaptive Fusion of Hyperspectral Likelihood Maps</papertitle>
              </a>

              <br>
              <a href="https://uzkent.github.io/">Burak Uzkent</a>, 
              <strong>Aneesh Rangnekar</strong>,
              <a href="https://people.rit.edu/mjhsma/">Matthew Hoffman</a>
              <br>
              <em>Perception Beyond the Visible Spectrum (PBVS-CVPRW)</em>, 2017
              <br>
              <a href="https://github.com/buzkent86/CVPRW17_Paper_code">code</a>
              <p></p>
              <p>
              We propose a novel real-time hyperspectral likelihood maps-aided target detection and tracking method (HLT) inspired by an adaptive hyperspectral sensor.
              </p>
            </td>
          </tr>

        </tbody></table>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This website is adapted from Jon Barron's template (<a href="https://jonbarron.info/">site</a>, <a href="https://github.com/jonbarron/jonbarron_website">source code</a>)
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
